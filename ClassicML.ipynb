{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f8c818dc7ce4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\romain.capocasa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gensim\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparsing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\romain.capocasa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gensim\\corpora\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# bring corpus classes directly into package namespace, to save some typing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mindexedcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIndexedCorpus\u001b[0m  \u001b[1;31m# noqa:F401 must appear before the other classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmmcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMmCorpus\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\romain.capocasa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gensim\\corpora\\indexedcorpus.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\romain.capocasa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gensim\\interfaces.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\romain.capocasa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gensim\\matutils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m   1022\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;31m# try to load fast, cythonized code if possible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1024\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_matutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_absolute_difference\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirichlet_expectation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\romain.capocasa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gensim\\_matutils.pyx\u001b[0m in \u001b[0;36minit gensim._matutils\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import preprocessor as tp\n",
    "import joblib\n",
    "import gensim\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "from SBM.TextProcessor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(\"data\", \"train_data.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(\"data\", \"test_data.csv\"))\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_no_bullying = len(train_data[train_data['oh_label'] == 0.0])\n",
    "nb_bullying = len(train_data[train_data['oh_label'] == 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar([\"No bullying\", \"Bullying\"], [nb_no_bullying,nb_bullying ])\n",
    "ax.set_ylabel(\"Nb Tweets\")\n",
    "fig.suptitle(\"Tweet class repartition\", fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get traint test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_data['Text'].to_numpy(), train_data['oh_label'].to_numpy()\n",
    "X_test, y_test = test_data['Text'].to_numpy(), test_data['oh_label'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TextProcessor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1b338734492b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m tp = TextProcessor(remove_punctuation=True, \n\u001b[0m\u001b[0;32m      2\u001b[0m                    \u001b[0mremove_stop_word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                    \u001b[0mmin_word_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                    special_token_method=SpecialTokenMethod.PREPROCESS)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TextProcessor' is not defined"
     ]
    }
   ],
   "source": [
    "tp = TextProcessor(remove_punctuation=True, \n",
    "                   remove_stop_word=True, \n",
    "                   min_word_size=2, \n",
    "                   special_token_method=SpecialTokenMethod.PREPROCESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pre = tp.fit_transform(X_train)\n",
    "X_test_pre = tp.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized Search - TFidf\n",
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                             ('nb', MultinomialNB())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'nb__alpha': (0.01, 0.1, 0.3, 0.5, 1.0,\n",
       "                                                      1.5, 2.0),\n",
       "                                        'tfidf__use_idf': (True, False)},\n",
       "                   scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'tfidf__use_idf' : (True, False),\n",
    "    'nb__alpha' : (0.01, 0.1,0.3, 0.5,1.0,1.5,2.0)\n",
    "}\n",
    "\n",
    "nb = Pipeline([('tfidf',TfidfVectorizer()), \n",
    "                ('nb',MultinomialNB())])\n",
    "\n",
    "random_search_nb = RandomizedSearchCV(nb, params,scoring='f1', n_iter=10, verbose=3, cv=5, n_jobs=-1)\n",
    "random_search_nb.fit(X_train_pre, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__use_idf': True, 'nb__alpha': 0.1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_nb.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nb = random_search_nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.81      0.78      2300\n",
      "         1.0       0.51      0.43      0.47      1070\n",
      "\n",
      "    accuracy                           0.69      3370\n",
      "   macro avg       0.63      0.62      0.62      3370\n",
      "weighted avg       0.68      0.69      0.68      3370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1868  432]\n",
      " [ 613  457]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models\\\\tfidf_nb.pkl']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(random_search_nb, os.path.join('saved_models','tfidf_nb.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                             ('rfc',\n",
       "                                              RandomForestClassifier())]),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'rfc__criterion': ('gini', 'entropy'),\n",
       "                                        'rfc__max_features': ('auto', 'sqrt',\n",
       "                                                              'log2'),\n",
       "                                        'rfc__min_samples_leaf': (1, 3, 5),\n",
       "                                        'rfc__min_samples_split': (2, 3, 4),\n",
       "                                        'rfc__n_estimators': (50, 100, 150,\n",
       "                                                              200)},\n",
       "                   scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'rfc__n_estimators' : (50,100,150,200),\n",
    "    'rfc__criterion' : (\"gini\", \"entropy\"),\n",
    "    'rfc__min_samples_split' : (2,3,4),\n",
    "    'rfc__min_samples_leaf' : (1,3,5),\n",
    "    'rfc__max_features' : ('auto', 'sqrt', 'log2')\n",
    "}\n",
    "\n",
    "rfc = Pipeline([('tfidf',TfidfVectorizer()), \n",
    "                ('rfc',RandomForestClassifier())])\n",
    "\n",
    "random_search_rfc = RandomizedSearchCV(rfc, params,scoring='f1', n_iter=50, verbose=3, cv=5, n_jobs=-1)\n",
    "random_search_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rfc__n_estimators': 100,\n",
       " 'rfc__min_samples_split': 4,\n",
       " 'rfc__min_samples_leaf': 1,\n",
       " 'rfc__max_features': 'auto',\n",
       " 'rfc__criterion': 'gini'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfc = random_search_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.96      0.89      2300\n",
      "         1.0       0.88      0.56      0.69      1070\n",
      "\n",
      "    accuracy                           0.84      3370\n",
      "   macro avg       0.85      0.76      0.79      3370\n",
      "weighted avg       0.84      0.84      0.83      3370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2219   81]\n",
      " [ 469  601]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models\\\\tfidf_rfc.pkl']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(random_search_rfc, os.path.join('saved_models','tfidf_rfc.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\romain.capocasa\\documents\\mse\\wem\\sbm\\wem_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 24 is smaller than n_iter=50. Running 24 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\romain.capocasa\\documents\\mse\\wem\\sbm\\wem_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.74286738 0.72849943 0.72748191 0.72020652\n",
      " 0.74286738 0.72849943        nan        nan 0.74781842 0.74144834\n",
      " 0.74353519 0.74031546 0.74781842 0.74144834        nan        nan\n",
      " 0.74306808 0.74471403 0.74401855 0.74287402 0.74331204 0.74471403]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                             ('svc', LinearSVC())]),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'svc__C': (0.5, 1.0, 2.0),\n",
       "                                        'svc__dual': (True, False),\n",
       "                                        'svc__penalty': ('l1', 'l2'),\n",
       "                                        'tfidf__use_idf': (True, False)},\n",
       "                   scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'tfidf__use_idf' : (True, False),\n",
    "    'svc__penalty' : ('l1', 'l2'),\n",
    "    'svc__C' : (0.5, 1.0, 2.0),\n",
    "    'svc__dual':(True,False)\n",
    "}\n",
    "\n",
    "svc = Pipeline([('tfidf',TfidfVectorizer()), \n",
    "                ('svc',LinearSVC())])\n",
    "\n",
    "random_search_svc = RandomizedSearchCV(svc, params,scoring='f1', n_iter=50, verbose=3, cv=5, n_jobs=-1)\n",
    "random_search_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__use_idf': True,\n",
       " 'svc__penalty': 'l2',\n",
       " 'svc__dual': True,\n",
       " 'svc__C': 1.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svc = random_search_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.92      0.89      2300\n",
      "         1.0       0.80      0.71      0.75      1070\n",
      "\n",
      "    accuracy                           0.85      3370\n",
      "   macro avg       0.84      0.81      0.82      3370\n",
      "weighted avg       0.85      0.85      0.85      3370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2111  189]\n",
      " [ 310  760]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models\\\\tfidf_svc.pkl']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(random_search_rfc, os.path.join('saved_models','tfidf_svc.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_token = [i.split() for i in X_train_pre]\n",
    "X_test_token = [i.split() for i in X_test_pre]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_dim = 200\n",
    "\n",
    "model_w2v = Word2Vec(X_train_token, vector_size=w2v_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v.save(os.path.join(\"saved_models\",\"word2vec.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('feminism', 0.9996818900108337),\n",
       " ('white', 0.9996761083602905),\n",
       " ('video', 0.9996713399887085),\n",
       " ('write', 0.9996585845947266),\n",
       " ('article', 0.9996237754821777),\n",
       " ('mention', 0.9995882511138916),\n",
       " ('understand', 0.9995764493942261),\n",
       " ('single', 0.9995691776275635),\n",
       " ('see', 0.9995645880699158),\n",
       " ('ask', 0.9995644092559814)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar(positive=\"racist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model_w2v.wv[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError:  # handling the case where the token is not in vocabulary\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and test matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13478, 200)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_train = len(X_train_token)\n",
    "\n",
    "wordvec_arrays_train = np.zeros((len_train, w2v_dim)) \n",
    "for i in range(len_train):\n",
    "    wordvec_arrays_train[i,:] = word_vector(X_train_token[i], w2v_dim)\n",
    "    \n",
    "wordvec_arrays_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3370, 200)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_test = len(X_test_token)\n",
    "\n",
    "wordvec_arrays_test = np.zeros((len_test, w2v_dim)) \n",
    "for i in range(len_test):\n",
    "    wordvec_arrays_test[i,:] = word_vector(X_test_token[i], w2v_dim)\n",
    "    \n",
    "wordvec_arrays_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomizedSearchCV - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=30,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'criterion': ('gini', 'entropy'),\n",
       "                                        'max_features': ('auto', 'sqrt',\n",
       "                                                         'log2'),\n",
       "                                        'min_samples_leaf': (1, 3, 5),\n",
       "                                        'min_samples_split': (2, 3, 4),\n",
       "                                        'n_estimators': (50, 100, 150, 200)},\n",
       "                   scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators' : (50,100,150,200),\n",
    "    'criterion' : (\"gini\", \"entropy\"),\n",
    "    'min_samples_split' : (2,3,4),\n",
    "    'min_samples_leaf' : (1,3,5),\n",
    "    'max_features' : ('auto', 'sqrt', 'log2')\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "random_search_rfc = RandomizedSearchCV(rfc, params,scoring='f1', n_iter=30, verbose=3, cv=5, n_jobs=-1)\n",
    "random_search_rfc.fit(wordvec_arrays_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 3,\n",
       " 'min_samples_leaf': 3,\n",
       " 'max_features': 'auto',\n",
       " 'criterion': 'gini'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfc = random_search_rfc.predict(wordvec_arrays_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.94      0.85      2300\n",
      "         1.0       0.76      0.45      0.56      1070\n",
      "\n",
      "    accuracy                           0.78      3370\n",
      "   macro avg       0.77      0.69      0.71      3370\n",
      "weighted avg       0.78      0.78      0.76      3370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2151  149]\n",
      " [ 593  477]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models\\\\w2v_rfc.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(random_search_rfc, os.path.join('saved_models','w2v_rfc.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomizedSearchCV - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\romain.capocasa\\documents\\mse\\wem\\sbm\\wem_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 12 is smaller than n_iter=50. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\romain.capocasa\\documents\\mse\\wem\\sbm\\wem_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.36211645 0.44397151 0.3618267         nan 0.42667167\n",
      " 0.48839392 0.42612482        nan 0.47660041 0.51821091 0.47643758]\n",
      "  warnings.warn(\n",
      "c:\\users\\romain.capocasa\\documents\\mse\\wem\\sbm\\wem_env\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LinearSVC(), n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'C': (0.5, 1.0, 2.0),\n",
       "                                        'dual': (True, False),\n",
       "                                        'penalty': ('l1', 'l2')},\n",
       "                   scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'penalty' : ('l1', 'l2'),\n",
    "    'C' : (0.5, 1.0, 2.0),\n",
    "    'dual':(True,False)\n",
    "}\n",
    "\n",
    "svc = LinearSVC()\n",
    "\n",
    "random_search_svc = RandomizedSearchCV(svc, params,scoring='f1', n_iter=50, verbose=3, cv=5, n_jobs=-1)\n",
    "random_search_svc.fit(wordvec_arrays_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': 'l1', 'dual': False, 'C': 2.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svc = random_search_svc.predict(wordvec_arrays_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.95      0.85      2300\n",
      "         1.0       0.79      0.38      0.51      1070\n",
      "\n",
      "    accuracy                           0.77      3370\n",
      "   macro avg       0.78      0.67      0.68      3370\n",
      "weighted avg       0.78      0.77      0.74      3370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2192  108]\n",
      " [ 662  408]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models\\\\w2v_svc.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(random_search_svc, os.path.join('saved_models','w2v_svc.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
